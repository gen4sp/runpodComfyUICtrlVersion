export default (prompt, options = {}) => {
  const {
    steps = 20,
    width = 1024,
    height = 1024,
    seed = Math.floor(Math.random() * 1000000000000000),
    cfg = 1,
    sampler_name = 'euler',
    scheduler = 'simple',
    useInputImage = true, // –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    useLora = false, // –í–∫–ª—é—á–µ–Ω–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ LoRA
    loras = [], // –ú–∞—Å—Å–∏–≤ LoRA –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
    guidance = 2.5,
    denoise = 1,
  } = options;

  // –ë–∞–∑–æ–≤—ã–µ —É–∑–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –≤—Å–µ–≥–¥–∞
  const workflow = {
    6: {
      inputs: {
        text: `${prompt}`,
        clip:
          useLora && loras.length > 0
            ? [`${400 + loras.length - 1}`, 1]
            : ['38', 0],
      },
      class_type: 'CLIPTextEncode',
      _meta: {
        title: 'CLIP Text Encode (Positive Prompt)',
      },
    },
    8: {
      inputs: {
        samples: ['31', 0],
        vae: ['39', 0],
      },
      class_type: 'VAEDecode',
      _meta: {
        title: 'VAE Decode',
      },
    },
    31: {
      inputs: {
        seed: seed,
        steps: steps,
        cfg: cfg,
        sampler_name: sampler_name,
        scheduler: scheduler,
        denoise: denoise,
        model:
          useLora && loras.length > 0
            ? [`${400 + loras.length - 1}`, 0]
            : ['37', 0],
        positive: ['35', 0],
        negative: ['135', 0],
        latent_image: useInputImage ? ['124', 0] : ['300', 0], // –£—Å–ª–æ–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ latent
      },
      class_type: 'KSampler',
      _meta: {
        title: 'KSampler',
      },
    },
    35: {
      inputs: {
        guidance: guidance,
        conditioning: useInputImage ? ['177', 0] : ['6', 0], // –£—Å–ª–æ–≤–Ω—ã–π –≤—ã–±–æ—Ä conditioning
      },
      class_type: 'FluxGuidance',
      _meta: {
        title: 'FluxGuidance',
      },
    },
    37: {
      inputs: {
        unet_name: 'flux1-dev-kontext_fp8_scaled.safetensors',
        weight_dtype: 'default',
      },
      class_type: 'UNETLoader',
      _meta: {
        title: 'Load Diffusion Model',
      },
    },
    38: {
      inputs: {
        clip_name1: 'clip_l.safetensors',
        clip_name2: 't5xxl_fp8_e4m3fn_scaled.safetensors',
        type: 'flux',
        device: 'default',
      },
      class_type: 'DualCLIPLoader',
      _meta: {
        title: 'DualCLIPLoader',
      },
    },
    39: {
      inputs: {
        vae_name: 'ae.safetensors',
      },
      class_type: 'VAELoader',
      _meta: {
        title: 'Load VAE',
      },
    },
    135: {
      inputs: {
        conditioning: ['6', 0],
      },
      class_type: 'ConditioningZeroOut',
      _meta: {
        title: 'ConditioningZeroOut',
      },
    },
    136: {
      inputs: {
        filename_prefix: 'ComfyUI',
        images: ['8', 0],
      },
      class_type: 'SaveImage',
      _meta: {
        title: 'Save Image',
      },
    },
  };

  // –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ LoRA, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞
  if (useLora && loras.length > 0) {
    console.log('üîß –î–æ–±–∞–≤–ª—è–µ–º LoRA —Ü–µ–ø–æ—á–∫—É:', loras.length, '–º–æ–¥–µ–ª–µ–π');

    // –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –≤–æ–∑–º–æ–∂–Ω–æ–π –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ WAN-–∞–¥–∞–ø—Ç–µ—Ä–æ–≤ —Å Flux
    const looksLikeWan = loras.some((l) =>
      /wan|t2v|lightx2v/i.test(l.name || '')
    );
    if (looksLikeWan) {
      console.warn(
        '‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã LoRA, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ WAN (wan/t2v/lightx2v). –î–ª—è –º–æ–¥–µ–ª–∏ Flux –æ–Ω–∏, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ LoRA, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å Flux.'
      );
    }

    // –°–æ–∑–¥–∞–µ–º –∫–∞—Å–∫–∞–¥ LoRA –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤, –Ω–∞—á–∏–Ω–∞—è —Å ID 400. –ö–∞—Å–∫–∞–¥–∏—Ä—É–µ–º –∏ model, –∏ clip
    loras.forEach((lora, index) => {
      const nodeId = 400 + index;
      const previousModel = index === 0 ? ['37', 0] : [`${400 + index - 1}`, 0];
      const previousClip = index === 0 ? ['38', 0] : [`${400 + index - 1}`, 1];

      workflow[nodeId] = {
        inputs: {
          lora_name: lora.name,
          strength_model: lora.strength || 1.0,
          strength_clip: lora.strength_clip || 1.0,
          model: previousModel,
          clip: previousClip,
        },
        class_type: 'LoraLoader',
        _meta: {
          title: `LoRA ${index + 1}: ${lora.name}`,
        },
      };

      console.log(
        `‚úÖ LoRA ${index + 1} –¥–æ–±–∞–≤–ª–µ–Ω–∞:`,
        lora.name,
        '—Å–∏–ª–∞:',
        lora.strength || 1.0,
        'clip:',
        lora.strength_clip || 1.0
      );
    });
  }

  // –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—Ö–æ–¥–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
  if (useInputImage) {
    // –£–∑–ª—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    workflow[142] = {
      inputs: {
        image: 'img1.png',
      },
      class_type: 'LoadImage',
      _meta: {
        title: 'Load Image',
      },
    };

    workflow[146] = {
      inputs: {
        direction: 'right',
        match_image_size: true,
        spacing_width: 0,
        spacing_color: 'white',
        image1: ['142', 0],
        image2: ['142', 0],
      },
      class_type: 'ImageStitch',
      _meta: {
        title: 'Image Stitch',
      },
    };

    workflow[42] = {
      inputs: {
        image: ['146', 0],
      },
      class_type: 'FluxKontextImageScale',
      _meta: {
        title: 'FluxKontextImageScale',
      },
    };

    workflow[200] = {
      inputs: {
        upscale_method: 'lanczos',
        width: width,
        height: height,
        crop: 'center',
        image: ['42', 0],
      },
      class_type: 'ImageScale',
      _meta: {
        title: 'Image Scale',
      },
    };

    workflow[124] = {
      inputs: {
        pixels: ['200', 0],
        vae: ['39', 0],
      },
      class_type: 'VAEEncode',
      _meta: {
        title: 'VAE Encode',
      },
    };

    workflow[173] = {
      inputs: {
        images: ['200', 0],
      },
      class_type: 'PreviewImage',
      _meta: {
        title: 'Preview Image',
      },
    };

    workflow[177] = {
      inputs: {
        conditioning: ['6', 0],
        latent: ['124', 0],
      },
      class_type: 'ReferenceLatent',
      _meta: {
        title: 'ReferenceLatent',
      },
    };
  } else {
    // –£–∑–µ–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—É—Å—Ç–æ–≥–æ latent –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è text-to-image –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    workflow[300] = {
      inputs: {
        width: width,
        height: height,
        batch_size: 1,
      },
      class_type: 'EmptyLatentImage',
      _meta: {
        title: 'Empty Latent Image',
      },
    };
  }

  return workflow;
};

// –ü—Ä–µ—Å–µ—Ç—ã LoRA —É–¥–∞–ª–µ–Ω—ã: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å Flux LoRA –∏ –ø–µ—Ä–µ–¥–∞–≤–∞–π—Ç–µ –∏—Ö –≤ options.loras
